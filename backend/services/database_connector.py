import json
import logging
from typing import Dict, Any, Optional, List
from datetime import datetime
try:
    import psycopg2
    from psycopg2.extras import RealDictCursor
    from psycopg2.pool import ThreadedConnectionPool
except ImportError:
    psycopg2 = None
    ThreadedConnectionPool = None

from .config_service import config
from models.app import App, Workflow, EnvironmentVariable, AppMode

class DatabaseConnector:
    """æ•°æ®åº“è¿æ¥å™¨ï¼Œç”¨äºä»Difyæ•°æ®åº“è·å–æ•°æ®"""
    
    def __init__(self):
        self.config = config
        self.pool = None
        self._init_connection_pool()
    
    def _init_connection_pool(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥æ± """
        if not self.config.is_database_enabled():
            return
        
        if psycopg2 is None:
            raise ImportError("psycopg2 æœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install psycopg2-binary")
        
        db_config = self.config.get_database_config()
        
        try:
            self.pool = ThreadedConnectionPool(
                minconn=1,
                maxconn=db_config.get('pool_size', 10),
                host=db_config['host'],
                port=db_config['port'],
                database=db_config['database'],
                user=db_config['username'],
                password=db_config['password'],
                sslmode=db_config.get('ssl_mode', 'prefer'),
                cursor_factory=RealDictCursor
            )
            logging.info("æ•°æ®åº“è¿æ¥æ± åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logging.error(f"æ•°æ®åº“è¿æ¥æ± åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        if not self.pool:
            raise RuntimeError("æ•°æ®åº“è¿æ¥æ± æœªåˆå§‹åŒ–")
        return self.pool.getconn()
    
    def return_connection(self, conn):
        """å½’è¿˜æ•°æ®åº“è¿æ¥"""
        if self.pool:
            self.pool.putconn(conn)
    
    def execute_query(self, query: str, params: tuple = None) -> List[Dict[str, Any]]:
        """æ‰§è¡Œæ•°æ®åº“æŸ¥è¯¢"""
        conn = None
        try:
            conn = self.get_connection()
            with conn.cursor() as cursor:
                cursor.execute(query, params)
                results = cursor.fetchall()
                return [dict(row) for row in results]
        except Exception as e:
            logging.error(f"æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {e}")
            raise
        finally:
            if conn:
                self.return_connection(conn)
    
    def get_app_by_id(self, app_id: str) -> Optional[App]:
        """æ ¹æ®åº”ç”¨IDè·å–åº”ç”¨ä¿¡æ¯"""
        if not self.config.is_database_enabled():
            return None
        
        db_config = self.config.get_database_config()
        table_name = db_config.get('tables', {}).get('apps', 'apps')
        
        query = f"""
            SELECT id, name, mode, icon, icon_type, icon_background, 
                   description, use_icon_as_answer_icon, tenant_id, 
                   created_at, updated_at
            FROM {table_name}
            WHERE id = %s
        """
        
        try:
            results = self.execute_query(query, (app_id,))
            if not results:
                logging.warning(f"æœªæ‰¾åˆ°åº”ç”¨IDä¸º {app_id} çš„åº”ç”¨")
                return None
            
            app_data = results[0]
            return App(
                id=app_data['id'],
                name=app_data['name'],
                mode=app_data['mode'],
                icon=app_data.get('icon', 'ğŸ¤–'),
                icon_type=app_data.get('icon_type', 'emoji'),
                icon_background=app_data.get('icon_background', '#FFEAD5'),
                description=app_data.get('description', ''),
                use_icon_as_answer_icon=app_data.get('use_icon_as_answer_icon', False),
                tenant_id=app_data['tenant_id']
            )
        except Exception as e:
            logging.error(f"è·å–åº”ç”¨ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def get_workflow_by_app_id(self, app_id: str) -> Optional[Workflow]:
        """æ ¹æ®åº”ç”¨IDè·å–å·¥ä½œæµ"""
        if not self.config.is_database_enabled():
            return None
            
        try:
            # æŸ¥è¯¢å·¥ä½œæµåŸºæœ¬ä¿¡æ¯ï¼ˆåŒ…æ‹¬ç¯å¢ƒå˜é‡ï¼‰
            workflow_query = """
                SELECT wf.id, wf.app_id, wf.version, wf.graph, wf.features, wf.environment_variables
                FROM workflows wf 
                WHERE wf.app_id = %s 
                ORDER BY wf.created_at DESC 
                LIMIT 1
            """
            
            results = self.execute_query(workflow_query, (app_id,))
            if not results:
                return None
            
            workflow_data = results[0]
            
            # è§£æJSONå­—æ®µ
            graph = self._parse_json_field(workflow_data['graph'])
            features = self._parse_json_field(workflow_data['features']) 
            environment_variables_data = self._parse_json_field(workflow_data['environment_variables']) or []
            
            # è§£æç¯å¢ƒå˜é‡
            env_vars = []
            for env_var_data in environment_variables_data:
                if isinstance(env_var_data, dict):
                    env_vars.append(EnvironmentVariable(
                        name=env_var_data.get('name', ''),
                        value=env_var_data.get('value', ''),
                        value_type=env_var_data.get('value_type', 'string')
                    ))
            
            # æ„é€ å·¥ä½œæµå¯¹è±¡
            workflow = Workflow(
                id=workflow_data['id'],
                app_id=workflow_data['app_id'],
                version=workflow_data['version'],
                graph=graph,
                features=features,
                environment_variables=env_vars
            )
            
            return workflow
            
        except Exception as e:
            logging.error(f"è·å–å·¥ä½œæµå¤±è´¥: {e}")
            return None
    
    def get_all_workflows(self) -> List[Workflow]:
        """è·å–æ‰€æœ‰å·¥ä½œæµ"""
        if not self.config.is_database_enabled():
            return []
            
        try:
            # æŸ¥è¯¢æ‰€æœ‰å·¥ä½œæµï¼ˆåŒ…æ‹¬ç¯å¢ƒå˜é‡ï¼‰
            workflow_query = """
                SELECT wf.id, wf.app_id, wf.version, wf.graph, wf.features, wf.environment_variables
                FROM workflows wf 
                ORDER BY wf.created_at DESC
                LIMIT 50
            """
            
            results = self.execute_query(workflow_query)
            workflows = []
            
            for workflow_data in results:
                try:
                    # è§£æJSONå­—æ®µ
                    graph = self._parse_json_field(workflow_data['graph'])
                    features = self._parse_json_field(workflow_data['features'])
                    environment_variables_data = self._parse_json_field(workflow_data['environment_variables']) or []
                    
                    # è§£æç¯å¢ƒå˜é‡
                    env_vars = []
                    for env_var_data in environment_variables_data:
                        if isinstance(env_var_data, dict):
                            env_vars.append(EnvironmentVariable(
                                name=env_var_data.get('name', ''),
                                value=env_var_data.get('value', ''),
                                value_type=env_var_data.get('value_type', 'string')
                            ))
                    
                    # æ„é€ å·¥ä½œæµå¯¹è±¡
                    workflow = Workflow(
                        id=workflow_data['id'],
                        app_id=workflow_data['app_id'],
                        version=workflow_data['version'],
                        graph=graph,
                        features=features,
                        environment_variables=env_vars
                    )
                    
                    workflows.append(workflow)
                    
                except Exception as e:
                    logging.error(f"è§£æå·¥ä½œæµæ•°æ®å¤±è´¥ (ID: {workflow_data.get('id', 'unknown')}): {e}")
                    continue
            
            return workflows
            
        except Exception as e:
            logging.error(f"è·å–æ‰€æœ‰å·¥ä½œæµå¤±è´¥: {e}")
            return []
    
    def get_environment_variables_by_app_id(self, app_id: str) -> List[EnvironmentVariable]:
        """æ ¹æ®åº”ç”¨IDè·å–ç¯å¢ƒå˜é‡"""
        if not self.config.is_database_enabled():
            return []
        
        query = """
            SELECT environment_variables
            FROM workflows
            WHERE app_id = %s
            ORDER BY created_at DESC
            LIMIT 1
        """
        
        try:
            results = self.execute_query(query, (app_id,))
            if not results:
                return []
            
            environment_variables_data = self._parse_json_field(results[0]['environment_variables']) or []
            environment_variables = []
            
            for env_var_data in environment_variables_data:
                if isinstance(env_var_data, dict):
                    environment_variables.append(
                        EnvironmentVariable(
                            name=env_var_data.get('name', ''),
                            value=env_var_data.get('value', ''),
                            value_type=env_var_data.get('value_type', 'string')
                        )
                    )
            
            return environment_variables
            
        except Exception as e:
            logging.error(f"è·å–ç¯å¢ƒå˜é‡å¤±è´¥: {e}")
            return []
    
    def get_workflow_nodes_by_workflow_id(self, workflow_id: str) -> List[Dict[str, Any]]:
        """æ ¹æ®å·¥ä½œæµIDè·å–èŠ‚ç‚¹ä¿¡æ¯"""
        if not self.config.is_database_enabled():
            return []
        
        db_config = self.config.get_database_config()
        nodes_table = db_config.get('tables', {}).get('workflow_nodes', 'workflow_nodes')
        
        query = f"""
            SELECT id, workflow_id, node_id, node_type, title, 
                   data, position_x, position_y
            FROM {nodes_table}
            WHERE workflow_id = %s
            ORDER BY node_id
        """
        
        try:
            results = self.execute_query(query, (workflow_id,))
            nodes = []
            
            for row in results:
                node_data = row.get('data', {})
                if isinstance(node_data, str):
                    node_data = json.loads(node_data)
                
                nodes.append({
                    'id': row['node_id'],
                    'type': row['node_type'],
                    'data': {
                        'type': row['node_type'],
                        'title': row.get('title', row['node_id']),
                        **node_data
                    },
                    'position': {
                        'x': row.get('position_x', 0),
                        'y': row.get('position_y', 0)
                    }
                })
            
            return nodes
        except Exception as e:
            logging.error(f"è·å–å·¥ä½œæµèŠ‚ç‚¹å¤±è´¥: {e}")
            return []
    
    def get_workflow_edges_by_workflow_id(self, workflow_id: str) -> List[Dict[str, Any]]:
        """æ ¹æ®å·¥ä½œæµIDè·å–è¾¹ä¿¡æ¯"""
        if not self.config.is_database_enabled():
            return []
        
        db_config = self.config.get_database_config()
        edges_table = db_config.get('tables', {}).get('workflow_edges', 'workflow_edges')
        
        query = f"""
            SELECT id, workflow_id, edge_id, source_node_id, target_node_id,
                   source_handle, target_handle, data
            FROM {edges_table}
            WHERE workflow_id = %s
            ORDER BY edge_id
        """
        
        try:
            results = self.execute_query(query, (workflow_id,))
            edges = []
            
            for row in results:
                edge_data = row.get('data', {})
                if isinstance(edge_data, str):
                    edge_data = json.loads(edge_data)
                
                edges.append({
                    'id': row['edge_id'],
                    'source': row['source_node_id'],
                    'target': row['target_node_id'],
                    'source_handle': row.get('source_handle', 'source'),
                    'target_handle': row.get('target_handle', 'target'),
                    **edge_data
                })
            
            return edges
        except Exception as e:
            logging.error(f"è·å–å·¥ä½œæµè¾¹å¤±è´¥: {e}")
            return []
    
    def test_connection(self) -> bool:
        """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
        if not self.config.is_database_enabled():
            return False
        
        try:
            results = self.execute_query("SELECT 1 as test")
            return len(results) > 0 and results[0]['test'] == 1
        except Exception as e:
            logging.error(f"æ•°æ®åº“è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥æ± """
        if self.pool:
            self.pool.closeall()
            logging.info("æ•°æ®åº“è¿æ¥æ± å·²å…³é—­")

    def _parse_json_field(self, json_field) -> dict:
        """è§£æJSONå­—æ®µ"""
        if json_field is None:
            return {}
        if isinstance(json_field, dict):
            return json_field
        if isinstance(json_field, str):
            try:
                return json.loads(json_field)
            except json.JSONDecodeError as e:
                logging.warning(f"JSONè§£æå¤±è´¥: {e}")
                return {}
        return {}

    def get_workflows_paginated(self, page: int = 1, page_size: int = 20, search: str = "") -> dict:
        """
        åˆ†é¡µè·å–å·¥ä½œæµåˆ—è¡¨
        :param page: é¡µç ï¼ˆä»1å¼€å§‹ï¼‰
        :param page_size: æ¯é¡µæ•°é‡
        :param search: æœç´¢å…³é”®è¯
        :return: åŒ…å«å·¥ä½œæµåˆ—è¡¨å’Œæ€»æ•°çš„å­—å…¸
        """
        if not self.config.is_database_enabled():
            return {"workflows": [], "total": 0}
            
        try:
            # è®¡ç®—åç§»é‡
            offset = (page - 1) * page_size
            
            # æ„å»ºæœç´¢æ¡ä»¶
            search_condition = ""
            search_params = []
            if search:
                search_condition = "WHERE (a.name ILIKE %s OR wf.app_id::text ILIKE %s)"
                search_params = [f"%{search}%", f"%{search}%"]
            
            # è·å–æ€»æ•°çš„æŸ¥è¯¢ - æŒ‰app_idå»é‡
            count_query = f"""
                SELECT COUNT(DISTINCT wf.app_id)
                FROM workflows wf
                LEFT JOIN apps a ON wf.app_id = a.id
                {search_condition}
            """
            
            # è·å–åˆ†é¡µæ•°æ®çš„æŸ¥è¯¢ - æ¯ä¸ªapp_idåªå–æœ€æ–°çš„å·¥ä½œæµ
            data_query = f"""
                SELECT DISTINCT ON (wf.app_id)
                    wf.id, wf.app_id, wf.version, wf.graph, wf.features, 
                    wf.environment_variables, wf.created_at,
                    a.name as app_name, a.description as app_description, a.mode as app_mode
                FROM workflows wf
                LEFT JOIN apps a ON wf.app_id = a.id
                {search_condition}
                ORDER BY wf.app_id, wf.created_at DESC
                LIMIT %s OFFSET %s
            """
            
            # æ‰§è¡Œæ€»æ•°æŸ¥è¯¢
            count_results = self.execute_query(count_query, search_params)
            total = count_results[0]['count'] if count_results else 0
            
            # æ‰§è¡Œåˆ†é¡µæŸ¥è¯¢
            data_params = search_params + [page_size, offset]
            data_results = self.execute_query(data_query, data_params)
            
            workflows = []
            for workflow_data in data_results:
                try:
                    # è§£æJSONå­—æ®µ
                    graph = self._parse_json_field(workflow_data['graph'])
                    features = self._parse_json_field(workflow_data['features'])
                    environment_variables_data = self._parse_json_field(workflow_data['environment_variables']) or []
                    
                    # è§£æç¯å¢ƒå˜é‡
                    env_vars = []
                    for env_var_data in environment_variables_data:
                        if isinstance(env_var_data, dict):
                            env_vars.append(EnvironmentVariable(
                                name=env_var_data.get('name', ''),
                                value=env_var_data.get('value', ''),
                                value_type=env_var_data.get('value_type', 'string')
                            ))
                    
                    # æ„é€ å·¥ä½œæµå¯¹è±¡
                    workflow = Workflow(
                        id=workflow_data['id'],
                        app_id=workflow_data['app_id'],
                        version=workflow_data['version'],
                        graph=graph,
                        features=features,
                        environment_variables=env_vars,
                        app_name=workflow_data.get('app_name') or f"å·¥ä½œæµ {workflow_data['app_id'][:8]}",
                        app_description=workflow_data.get('app_description') or '',
                        app_mode=workflow_data.get('app_mode') or 'workflow'
                    )
                    
                    workflows.append(workflow)
                    
                except Exception as e:
                    logging.error(f"è§£æå·¥ä½œæµæ•°æ®å¤±è´¥ (ID: {workflow_data.get('id', 'unknown')}): {e}")
                    continue
            
            return {
                "workflows": workflows,
                "total": total
            }
            
        except Exception as e:
            logging.error(f"åˆ†é¡µè·å–å·¥ä½œæµå¤±è´¥: {e}")
            return {"workflows": [], "total": 0}


# å…¨å±€æ•°æ®åº“è¿æ¥å™¨å®ä¾‹
database_connector = DatabaseConnector() 