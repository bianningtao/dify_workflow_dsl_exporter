import json
import yaml
import logging
import os
import shutil
from datetime import datetime
from typing import Dict, Any, Optional, List
from pathlib import Path

from .config_service import config
from models.app import App, Workflow, EnvironmentVariable, AppMode

class ManualImportService:
    """æ‰‹åŠ¨å¯¼å…¥æœåŠ¡ï¼Œç”¨äºç®¡ç†æ‰‹åŠ¨ä¸Šä¼ çš„å·¥ä½œæµæ•°æ®"""
    
    def __init__(self):
        self.config = config
        self.data_dir = None
        self.backup_dir = None
        self._init_storage()
    
    def _init_storage(self):
        """åˆå§‹åŒ–å­˜å‚¨é…ç½®"""
        if not self.config.is_manual_enabled():
            return
        
        manual_config = self.config.get_manual_config()
        
        if manual_config.get('storage_type') == 'file':
            file_config = manual_config.get('file_storage', {})
            self.data_dir = Path(file_config.get('data_dir', './data'))
            self.backup_dir = Path(file_config.get('backup_dir', './data/backups'))
            
            # åˆ›å»ºç›®å½•
            self.data_dir.mkdir(parents=True, exist_ok=True)
            if file_config.get('auto_backup', True):
                self.backup_dir.mkdir(parents=True, exist_ok=True)
            
            logging.info(f"æ‰‹åŠ¨å¯¼å…¥æœåŠ¡åˆå§‹åŒ–æˆåŠŸï¼Œæ•°æ®ç›®å½•: {self.data_dir}")
    
    def import_workflow_data(self, app_id: str, workflow_data: Dict[str, Any], format_type: str = 'json') -> bool:
        """å¯¼å…¥å·¥ä½œæµæ•°æ®"""
        if not self.config.is_manual_enabled():
            raise RuntimeError("æ‰‹åŠ¨å¯¼å…¥åŠŸèƒ½æœªå¯ç”¨")
        
        try:
            # éªŒè¯æ•°æ®æ ¼å¼
            self._validate_workflow_data(workflow_data)
            
            # ä¿å­˜æ•°æ®
            self._save_workflow_data(app_id, workflow_data, format_type)
            
            logging.info(f"å·¥ä½œæµæ•°æ®å¯¼å…¥æˆåŠŸ: {app_id}")
            return True
            
        except Exception as e:
            logging.error(f"å·¥ä½œæµæ•°æ®å¯¼å…¥å¤±è´¥: {e}")
            return False
    
    def import_from_file(self, app_id: str, file_path: str) -> bool:
        """ä»æ–‡ä»¶å¯¼å…¥å·¥ä½œæµæ•°æ®"""
        if not self.config.is_manual_enabled():
            raise RuntimeError("æ‰‹åŠ¨å¯¼å…¥åŠŸèƒ½æœªå¯ç”¨")
        
        file_path = Path(file_path)
        
        if not file_path.exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        try:
            # æ ¹æ®æ–‡ä»¶æ‰©å±•åç¡®å®šæ ¼å¼
            if file_path.suffix.lower() in ['.yaml', '.yml']:
                with open(file_path, 'r', encoding='utf-8') as f:
                    workflow_data = yaml.safe_load(f)
                format_type = 'yaml'
            elif file_path.suffix.lower() == '.json':
                with open(file_path, 'r', encoding='utf-8') as f:
                    workflow_data = json.load(f)
                format_type = 'json'
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path.suffix}")
            
            return self.import_workflow_data(app_id, workflow_data, format_type)
            
        except Exception as e:
            logging.error(f"ä»æ–‡ä»¶å¯¼å…¥å¤±è´¥: {e}")
            return False
    
    def _validate_workflow_data(self, workflow_data: Dict[str, Any]) -> None:
        """éªŒè¯å·¥ä½œæµæ•°æ®æ ¼å¼"""
        required_fields = ['app', 'workflow']
        
        for field in required_fields:
            if field not in workflow_data:
                raise ValueError(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
        
        app_data = workflow_data['app']
        workflow_config = workflow_data['workflow']
        
        # éªŒè¯åº”ç”¨æ•°æ®
        if 'name' not in app_data:
            raise ValueError("åº”ç”¨æ•°æ®ç¼ºå°‘nameå­—æ®µ")
        if 'mode' not in app_data:
            raise ValueError("åº”ç”¨æ•°æ®ç¼ºå°‘modeå­—æ®µ")
        
        # éªŒè¯å·¥ä½œæµæ•°æ®
        if 'graph' not in workflow_config:
            raise ValueError("å·¥ä½œæµæ•°æ®ç¼ºå°‘graphå­—æ®µ")
        
        graph = workflow_config['graph']
        if 'nodes' not in graph:
            raise ValueError("å·¥ä½œæµå›¾ç¼ºå°‘nodeså­—æ®µ")
        if 'edges' not in graph:
            raise ValueError("å·¥ä½œæµå›¾ç¼ºå°‘edgeså­—æ®µ")
    
    def _save_workflow_data(self, app_id: str, workflow_data: Dict[str, Any], format_type: str) -> None:
        """ä¿å­˜å·¥ä½œæµæ•°æ®åˆ°æ–‡ä»¶"""
        if not self.data_dir:
            raise RuntimeError("æ•°æ®ç›®å½•æœªåˆå§‹åŒ–")
        
        # å¤‡ä»½ç°æœ‰æ•°æ®
        existing_file = self.data_dir / f"{app_id}.{format_type}"
        if existing_file.exists():
            self._backup_existing_data(app_id, format_type)
        
        # ä¿å­˜æ–°æ•°æ®
        if format_type == 'yaml':
            with open(existing_file, 'w', encoding='utf-8') as f:
                yaml.dump(workflow_data, f, allow_unicode=True, default_flow_style=False)
        else:
            with open(existing_file, 'w', encoding='utf-8') as f:
                json.dump(workflow_data, f, indent=2, ensure_ascii=False)
    
    def _backup_existing_data(self, app_id: str, format_type: str) -> None:
        """å¤‡ä»½ç°æœ‰æ•°æ®"""
        if not self.backup_dir:
            return
        
        existing_file = self.data_dir / f"{app_id}.{format_type}"
        if not existing_file.exists():
            return
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_file = self.backup_dir / f"{app_id}_{timestamp}.{format_type}"
        
        shutil.copy2(existing_file, backup_file)
        logging.info(f"å·²å¤‡ä»½ç°æœ‰æ•°æ®: {backup_file}")
    
    def get_app_by_id(self, app_id: str) -> Optional[App]:
        """æ ¹æ®åº”ç”¨IDè·å–åº”ç”¨ä¿¡æ¯"""
        if not self.config.is_manual_enabled():
            return None
        
        workflow_data = self._load_workflow_data(app_id)
        if not workflow_data:
            return None
        
        try:
            app_data = workflow_data['app']
            return App(
                id=app_id,
                name=app_data.get('name', f'å·¥ä½œæµåº”ç”¨ {app_id[:8]}'),
                mode=app_data.get('mode', AppMode.WORKFLOW.value),
                icon=app_data.get('icon', 'ğŸ¤–'),
                icon_type=app_data.get('icon_type', 'emoji'),
                icon_background=app_data.get('icon_background', '#FFEAD5'),
                description=app_data.get('description', ''),
                use_icon_as_answer_icon=app_data.get('use_icon_as_answer_icon', False),
                tenant_id=app_data.get('tenant_id', '')
            )
        except Exception as e:
            logging.error(f"è§£æåº”ç”¨æ•°æ®å¤±è´¥: {e}")
            return None
    
    def get_workflow_by_app_id(self, app_id: str) -> Optional[Workflow]:
        """æ ¹æ®åº”ç”¨IDè·å–å·¥ä½œæµä¿¡æ¯"""
        if not self.config.is_manual_enabled():
            return None
        
        workflow_data = self._load_workflow_data(app_id)
        if not workflow_data:
            return None
        
        try:
            workflow_config = workflow_data['workflow']
            
            # è§£æç¯å¢ƒå˜é‡
            environment_variables = []
            for env_var in workflow_config.get('environment_variables', []):
                environment_variables.append(
                    EnvironmentVariable(
                        name=env_var['name'],
                        value=env_var['value'],
                        value_type=env_var.get('value_type', 'string')
                    )
                )
            
            return Workflow(
                id=workflow_config.get('id', app_id),
                app_id=app_id,
                version=workflow_config.get('version', '1.0'),
                graph=workflow_config.get('graph', {}),
                features=workflow_config.get('features', {}),
                environment_variables=environment_variables
            )
        except Exception as e:
            logging.error(f"è§£æå·¥ä½œæµæ•°æ®å¤±è´¥: {e}")
            return None
    
    def _load_workflow_data(self, app_id: str) -> Optional[Dict[str, Any]]:
        """åŠ è½½å·¥ä½œæµæ•°æ®"""
        if not self.data_dir:
            return None
        
        # å°è¯•ä¸åŒçš„æ–‡ä»¶æ ¼å¼
        formats = ['json', 'yaml', 'yml']
        
        for fmt in formats:
            file_path = self.data_dir / f"{app_id}.{fmt}"
            if file_path.exists():
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        if fmt in ['yaml', 'yml']:
                            return yaml.safe_load(f)
                        else:
                            return json.load(f)
                except Exception as e:
                    logging.error(f"åŠ è½½æ•°æ®æ–‡ä»¶å¤±è´¥: {file_path} - {e}")
                    continue
        
        return None
    
    def get_available_apps(self) -> List[str]:
        """è·å–å¯ç”¨çš„åº”ç”¨IDåˆ—è¡¨"""
        if not self.config.is_manual_enabled() or not self.data_dir:
            return []
        
        app_ids = []
        for file_path in self.data_dir.glob('*'):
            if file_path.is_file() and file_path.suffix.lower() in ['.json', '.yaml', '.yml']:
                app_id = file_path.stem
                app_ids.append(app_id)
        
        return sorted(app_ids)
    
    def delete_app_data(self, app_id: str) -> bool:
        """åˆ é™¤åº”ç”¨æ•°æ®"""
        if not self.config.is_manual_enabled() or not self.data_dir:
            return False
        
        try:
            # å¤‡ä»½æ•°æ®
            self._backup_existing_data(app_id, 'json')
            self._backup_existing_data(app_id, 'yaml')
            self._backup_existing_data(app_id, 'yml')
            
            # åˆ é™¤æ•°æ®æ–‡ä»¶
            formats = ['json', 'yaml', 'yml']
            deleted = False
            
            for fmt in formats:
                file_path = self.data_dir / f"{app_id}.{fmt}"
                if file_path.exists():
                    file_path.unlink()
                    deleted = True
                    logging.info(f"å·²åˆ é™¤æ•°æ®æ–‡ä»¶: {file_path}")
            
            return deleted
            
        except Exception as e:
            logging.error(f"åˆ é™¤åº”ç”¨æ•°æ®å¤±è´¥: {e}")
            return False
    
    def update_app_data(self, app_id: str, workflow_data: Dict[str, Any]) -> bool:
        """æ›´æ–°åº”ç”¨æ•°æ®"""
        return self.import_workflow_data(app_id, workflow_data)
    
    def export_app_data(self, app_id: str, format_type: str = 'yaml') -> Optional[str]:
        """å¯¼å‡ºåº”ç”¨æ•°æ®"""
        workflow_data = self._load_workflow_data(app_id)
        if not workflow_data:
            return None
        
        try:
            if format_type == 'yaml':
                return yaml.dump(workflow_data, allow_unicode=True, default_flow_style=False)
            else:
                return json.dumps(workflow_data, indent=2, ensure_ascii=False)
        except Exception as e:
            logging.error(f"å¯¼å‡ºåº”ç”¨æ•°æ®å¤±è´¥: {e}")
            return None
    
    def get_app_stats(self) -> Dict[str, Any]:
        """è·å–åº”ç”¨ç»Ÿè®¡ä¿¡æ¯"""
        if not self.config.is_manual_enabled() or not self.data_dir:
            return {}
        
        stats = {
            'total_apps': 0,
            'total_size': 0,
            'last_updated': None,
            'formats': {'json': 0, 'yaml': 0, 'yml': 0}
        }
        
        for file_path in self.data_dir.glob('*'):
            if file_path.is_file() and file_path.suffix.lower() in ['.json', '.yaml', '.yml']:
                stats['total_apps'] += 1
                stats['total_size'] += file_path.stat().st_size
                
                format_key = file_path.suffix.lower().lstrip('.')
                stats['formats'][format_key] += 1
                
                modified_time = datetime.fromtimestamp(file_path.stat().st_mtime)
                if not stats['last_updated'] or modified_time > stats['last_updated']:
                    stats['last_updated'] = modified_time
        
        return stats


# å…¨å±€æ‰‹åŠ¨å¯¼å…¥æœåŠ¡å®ä¾‹
manual_import_service = ManualImportService() 